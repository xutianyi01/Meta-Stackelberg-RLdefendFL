# Meta Stackelberg Game: Robust Federated Learning against Adaptive and Mixed Poisoning Attacks

This repository contains the code for the paper:

**Meta Stackelberg Game: Robust Federated Learning against Adaptive and Mixed Poisoning Attacks**  
ðŸ“„ [arXiv:2410.17431](https://arxiv.org/abs/2410.17431)


## Files
- `Mixed_RLdefendFL4.ipynb` â€” Main notebook for the Meta-Stackelberg robust FL defense.
- `BackdoorFL_cifar10.ipynb` â€” RL-based backdoor attack baseline on CIFAR-10.
- `BackdoorFL_mnist.ipynb` â€” RL-based backdoor attack baseline on MNIST.


## Related Work

For more **code-level details** (attack implementations and training procedures), please check:

- Henger Li, Xiaolin Sun, Zizhan Zheng. **Learning to Attack Federated Learning: A Model-Based Reinforcement Learning Attack Framework.** *NeurIPS 2022*.  
  Paper: https://proceedings.neurips.cc/paper_files/paper/2022/file/e2ef0cae667dbe9bfdbcaed1bd91807b-Paper-Conference.pdf
  Code: https://github.com/SliencerX/Learning-to-Attack-Federated-Learning  

- Henger Li, Chen Wu, Sencun Zhu, Zizhan Zheng. **Learning to Backdoor Federated Learning.** *ICLR 2023 Workshop on Backdoor Attacks and Defenses in Machine Learning (BANDS).*  
  arXiv: https://arxiv.org/abs/2303.03320
  Code: https://github.com/HengerLi/RLBackdoorFL
